
\documentclass[final,5p,times]{cas-dc}

\usepackage{siunitx}
\usepackage[font=footnotesize, justification = centering]{caption}
\usepackage[font=footnotesize]{subcaption}
\usepackage{amsmath}
\usepackage[ruled,linesnumbered]{algorithm2e} %for writing pseudocodes
\usepackage{graphicx}
\usepackage{changepage}

\journal{Computer Communications}

\begin{document}
	\begin{frontmatter}
		%a complete algorithm which places controllers and is dynamic based on traffic
		\title{Versatility in Controller Placement Approaches through Graph Theory and Informed Search Techniques}
		
		\author[1]{Talha Ibn Aziz\corref{cor1}}
		\ead{talhaibnaziz@iut-dhaka.edu}
		
		\author[1]{Tasneea Hossain}
		\ead{tasneeahossain11@gmail.com}
		
		\author[1]{Md Sakhawat Hossen}
		\ead{sakhawat@iut-dhaka.edu}
		
		\author[1]{Muhammad Mahbub Alam}
		\ead{mma@iut-dhaka.edu}
		
		\cortext[cor1]{Corresponding author}
		
		\address[1]{Department of Computer Science and Engineering, Islamic University of Technology, Dhaka, Bangladesh}
		
		
		\begin{abstract}
			Software Defined-Networks (SDNs) decouple the traditional protocol stack into the control plane and the data plane consisting of - controllers and switches, respectively. The controllers are placed in the network considering numerous fundamental parameters like flow-setup latency, switch-controller control traffic, route synchronization latency, reliability, and security. While many researchers address the resultant Controller Placement Problem (CPP), very few provide a thorough and efficient process that considers multiple core parameters. In this paper, we propose three algorithms to cluster the network, place controllers, and assign switches dynamically to controllers in polynomial time. Extensive simulations on two hundred and forty-three (243) existing network topologies suggest that our approach outperforms current state-of-the-art controller placement algorithms in terms of flow-setup latency and traffic-awareness.
		\end{abstract}
		\begin{keyword}
			SDN \sep CPP \sep controllers \sep flow-setup \sep latency \sep control traffic
		\end{keyword}
		
	\end{frontmatter}

	\section{Introduction}
	The booming Internet usage growth and integration of a plethora of IoT devices into the network system generates a shortage of resources in terms of network management. Furthermore, the amalgamation of different types of switches from various vendors increases the complexity of network configuration, which is already troublesome. In light of the above-mentioned predicament, a novel network architecture known as Software Defined Network (SDN) is proposed, which has been a center-stage of cutting-edge research for the past few decades. SDNs distribute the functionalities of the traditional network layer switches to simplify network management and configuration, making efficient use of scarce resources. The forwarding capabilities are retained by the switches while new agents are introduced as the decision making entities. These authoritative devices - namely \textit{controllers}, have superior processing power and memory compared to the SDN switches, which are simplified in terms of both costs and design.
	
	The original SDN architecture \cite{greene2009tr10} includes a single controller, resulting in the formation of bottle-necks, single point of failure, and scalability issues \cite{scalability2013dixit, scalability2013yeganeh}, when the network size increases. Consequently, the multiple-controller architecture is proposed; however, the solution comes with its own NP-Hard Controller Placement Problem (CPP). The CPP deals with placing an optimal number of controllers to optimize one or more constraints - network latencies, deployment costs, energy consumption, reliability, and resilience \cite{zhang2017survey, singh2018survey, cox2017survey}. In this paper, we propose a novel controller assignment method which minimizes the following:
	
	\begin{adjustwidth}{0.5cm}{}
		\textbf{(1) Latency:} We minimize two latencies simultaneously, namely, \textit{route synchronization latency} and \textit{flow-setup latency}. When there is a change in the network, the concerned controllers and switches are notified immediately. The delay produced here is called the route-synchronization latency. When a new flow arrives at a switch, the flow-setup process is initiated through which the corresponding controller calculates a new path and notifies concerned switches. The total delay incurred through this process is called the flow-setup latency. \\
		\textbf{(2) Controller response time and Load imbalance:} Due to the influx of numerous new flows, several query packets from multiple switches impose on the controllers. The great volume of processing required by a controller to facilitate the smooth operation of the network is called the \textit{load of a controller}. Imbalanced distribution of load can lead to an exponential increase in controller response times.
	\end{adjustwidth}
	The processing delay of SDN switches is significantly reduced compared to traditional networks and propagation latencies are negligible due to greater wave propagation velocities. Therefore, the overall flow-setup latency relies primarily on transmission latency and queuing latency of control packets \cite{forouzan2006data}. Our proposed method aims to divide the network into \textit{k} balanced clusters and place a controller in each cluster to reduce transmission latency. Furthermore, the controller response time is improved through dynamic load balancing, which reduces queuing latency. 
	
	Most research approaches perform optimization of a specific latency or parameter instead of providing a complete system, while a few of them address multiple parameters simultaneously \cite{lange2015multi, sallahi2015optimal}. However, they either provide exhaustive solutions or reduce accuracy greatly to improve efficiency in terms of time and memory complexity. To the best of our knowledge, there is no such method that clusters the network, place controllers considering both inter-controller and intra-controller latency, and assigns switches dynamically to minimize flow setup latency, route synchronization latency, load imbalance, and controller response times in polynomial complexity. Therefore, we develop multiple algorithms to address the problem at hand, and our main contributions are summarized as follows:
	\begin{itemize}
		\item We minimize overall flow-setup latency and route synchronization latency while placing controllers. Furthermore, we provide a way to trade-off between inter-controller and intra-controller latencies for network managers.
		
		\item We develop three polynomial-time algorithms to cluster the network, place controllers and balance controller loads. We also suggest an optimal number of controllers.
		
		\item Our proposed method is traffic-aware and reduces controller response time by balancing controller loads in real-time. It can be improved further to work with any network parameter.
		
		\item We perform simulations on 243 existing network topologies and our simulations show that our method outperforms state-of-the-art algorithms for controller placement in terms of flow-setup latency, controller response time, and load balancing.
	\end{itemize}
	
 	
 	The remainder of our paper consists of the background and related works in Section \ref{background}, the problem formulation in Section \ref{sysMod}, the detailed proposed mechanism in Section \ref{proposal}, the performance analysis in Section \ref{simulations}, the simulation results in Section \ref{simulationResults}, and the conclusion in Section \ref{conclusion}.
	
	\section{Background and Related Works} \label{background}
	Several researches have addressed multiple aspects of the Controller Placement Problem (CPP) in the last decade. Heller. et al. \cite{heller2012latency} study the effects of different latencies on overall network throughput through exhaustive controller deployment and generate two essential questions - \textit{How many controllers are needed?} and \textit{Where in the topology should they go?} Solutions to the CPP address these questions by optimizing various parameters when placing controllers, namely - switch-controller and controller-controller delays, route synchronization latency, flow-setup latency, reliability and resilience, deployment costs, traffic-awareness, etc. Some of the notable works are mentioned in this section along with the parameters they addressed.
	
	Li et al. \cite{li2020latency} minimize the average switch-controller transmission delay to achieve effective deployment of multiple controllers in a continuous two-dimensional space by adopting the PSO (particle swarm optimization). Das et al. \cite{das2020latency} presents a Steiner tree-based model that analyses the network state synchronization delay between the controllers by minimizing inter-controller latency. The model addresses both failure-free and post-failure scenarios to make the placement resilient. Multiple researchers explicitly address the reliability and resilience of multiple controller placement. Hu et al. \cite{hu2013reliability} introduces a metric - expected percentage of control path loss and formulates the reliability-aware control placement problem. Zhang et al. \cite{zhang2011resilience} propose a min-cut based graph partitioning algorithm to place controllers, which aims at maximizing the resilience of the network and shows its advantage over greedy algorithms. Ashrafi et al. \cite{ashrafi2020reliability} address this issue by developing a mathematical model to minimize latency while taking all failure scenarios and scalability into consideration. Fan et al. \cite{fan2020reliability} minimize the average drop-rate of flow set-up requests due to single-link failure using two algorithms - Reliability Aware Controller Placement (RAC) and Fast-RAC (FRAC). Yang et al. \cite{yang2020security} introduce a greedy heuristic algorithm for single-link failures and the Monte Carlo Simulation for multi-link failures
	
	Placing minimal controllers makes the SDN vulnerable to failures and security attacks. Contrarily, deploying maximal controllers reduces delays, response times of the controllers, and throughput of the network; it is, however, not feasible in terms of cost and inefficient in terms of resources. Sallahi et al. \cite{sallahi2015optimal} propose a mathematical model to determine the optimal number of controllers and their locations in a network while minimizing the cost of the SDN. Chaudhary et al. \cite{chaudhary2020cost} develop the Placement Availability Resilient Controller (PARC) scheme to provide a stable partitioning of the network, a co-operative game theory-based localization of controllers, and an optimal controller number calculation including extra backup controllers while minimizing network cost. Several research proposals also address the wireless paradigm of SDN - Dvir et al. \cite{dvir2019wireless} minimize propagation latency, maximize throughput, and link failure probability while placing controllers. Toufga et al. \cite{toufga2020vehicle} propose and Integer Linear Programming (ILP) based placement method which dynamically changes controller placement based on road traffic fluctuations for Software-Defined Vehicular Networks (SDVNs). Papa et al. \cite{papa2020satellite} place controllers in large-scale satellite networks to minimize the average flow setup latency with respect to varying traffic demands.
	
	The fluctuations of switch-controller control traffic impose varying loads on the controllers. Consequently, the performance of a controller is significantly reduced when its load exceeds its processing capacity. Wang et al \cite{wang2011load} distributes the traffic using wildcard rules on supported switches to transfer traffic to OpenFlow \cite{hu2014survey} server replicas. Yao et al. \cite{yao2014capacitated} define the Capacitated Controller Placement Problem (CCPP) which takes loads of controllers into consideration and also introduces an efficient algorithm to solve it. Yao et al. \cite{yao2015controller} propose a multi-controller load balancing approach called HybridFlow for software-defined wireless networks, which is a flow-based dynamic solution. Chen et al. \cite{chen2018load} propose a load balancing scheme that provides quality of service (QoS) for machine-to-machine (M2M) networks through traffic identification and rerouting. Choumas et al. \cite{choumas2020oittraffic} assess and explore control-traffic minimization and devise multiple heuristic algorithms to propose an efficient solution. Coronado et al. \cite{coronado2017wiload} propose - \textit{Wi-Balance}, an algorithm that balances traffic load and maintains an equal division of network resources.
	Qilin et al. \cite{qilin2015load} improve traffic scheduling by reducing the number of flow tables. Schutz et al. \cite{schutz2020load} formalizes the CPP mathematically to place controllers while keeping a balanced load distribution.
	
	The explosive amount of data traffic generated due to the advent of the Internet of Things (IoT) and improvement of Mobile networks demands better and more efficient load balancing algorithms. Under these circumstances, multiple variations of stable matching algorithms are proposed to ensure maximum utilization of available resources. Wang et al. in \cite{wang2016load} propose a combination of matching theory and conditional games to perform load balancing of controllers. Filali et al. \cite{filali2018sdn} formulate the CCPP as a one-to-many matching game and use a well-known stable matching algorithm - Multistage Deferred Acceptance Algorithm (MSDA) \cite{fragiadakis2016matching} to solve it.
	
	\section{Problem Formulation and Assumptions} \label{sysMod}
	Systematic segregation of the network layer into control and data planes require the division of larger networks into multiple sub-networks, where each sub-network is governed by a single controller.
	
	%sets of switches eqn and sub-network=> cluster
	We represent the network as a weighted bi-directional graph $G=(S,E)$, where $S$ represents the set of switches (or nodes) and $E$ represents the set of links (or edges) between the switches. The weights of the edges represent the transmission delays, which is the reciprocal of the bandwidth of the links. The graph $G$ is clustered into $k$ mutually exclusive and collectively exhaustive sets of switches (i.e., sub-networks) denoted by $S_i$, where $i=1,2,....,k$. Switches in a sub-network forward packets following a set of rules, using flow-tables. However, when a \textit{new flow} arrives, the source switch sends a query packet to the controller of the sub-network. The controller notifies the concerned switches in the path about the new rule. It also notifies the controller of a switch in the path if the switch is not in its own sub-network. The flow setup procedure for a switch can be divided into three phases, 1) the switch sends a query packet to the its controller, 2) after a period of queuing delay (if any), the controller processes the query and takes a routing decision, and finally, 3) the controller informs the new rule to all the switches in the path. The total time required to complete all the three phases is called the \textit{flow-setup latency}.
	
	The delay incurred by the first phase of the flow-setup procedure depends on the link between the concerned switch and controller. Contrarily, the delay in the second phase depends on the time that a controller takes to take a routing decision+, and is called the \textit{controller response time}. The response time can be calculated if the \textit{loads} of the switches and the controllers, and the \textit{processing power} of the controllers are known. The total number of query packets generated by a switch in a unit time is the load of the switch (hereafter referred to as \textit{switch-load}) and the total number of query packets generated by all the switches in a sub-network is the load of the controller (hereafter referred to as \textit{controller-load}).
	
	We assume that both the arrival times and the service times of the queries follow a Poisson process like \cite{wang2016load}. Therefore, the delays associated with the queries at the controller can be modeled as an M/M/1 queue and the average system time (i.e., the summation of waiting time and service time) can be determined using Little's Law as follows \cite{wang2016load}:
	
	\begin{equation} \label{eqn:cresponse}
	RT_{avg} = \frac{1}{(Power_{C_i} - Load_{C_i})}
	\end{equation}
	where $Power_{C_i}$ and $Load_{C_i}$ of any controller $C_i$ in the network are the maximum processing power and the load of the controller, respectively .
	
	When all the controllers are working at their maximum capacity, the imbalance of the network load does not play a role here. When one switch is overloaded and other switches
	
	For a heavily loaded network the controllers are processing at or close to their maximum capacity. Consequently, a balance or imbalance of loads do not play a vital role to reduce controller response times. However, when some controllers are overloaded and others are underloaded, balancing their loads can improve both the waiting time and processing time. In this case, assigning loads to controllers according to their processing capacity can significantly improve their response times.
	
	The third phase of the flow-setup procedure depends on both the controller-switch and controller-controller latencies of the involved controllers and their respective switches that are in the flow-path. Furthermore, the time required for a controller to announce any changes among the switches in its sub-network, is called the route-synchronization latency, which is also determined by the controller-switch latency. Therefore, our goal is to divide the network into clusters while,
	\begin{enumerate}
		\item placing controllers to minimize the overall flow-setup and route synchronization latencies, and
		\item dynamically balancing the loads among the controllers to reduce average controller response times.
	\end{enumerate}
	For simplicity, we assume that the processing delay of all switch-to-controller control packets is negligible. Furthermore, a controller can only be placed on a switch location and all the controllers have identical processing capacity.
	
	%Flow of the problem formulation should be as follows: first paragraph expresses the network as a graph with nodes and edges (what they represent as well). The second part defines how a network will be divided into sub-networks or clusters (may use the notations S_{i=1,2,...,k}). The third part explains in entirity how the flow setup latency needs to be minimized and how the route synchronization and load imbalance plays a role here and how each of these are minimized (without going into our proposed algorithm). Then start with our goals and the two points that we have already mentioned.
	
	\section{Proposed Methodology} \label{proposal}
	
	In our proposed method, we develop three algorithms - Latency-based Clustering Algorithm (LCA), Latency-based Controller Selection Algorithm (LCSA), and Best-first-search Load Balancing Algorithm (BLBA). LBCA clusters the network into a given number of sub-networks ($k$) and CSA places a controller in each of the sub-networks, resulting in a static controller-switch assignment. BLBA is a dynamic load balancing algorithm that periodically reassigns switches to avoid over-burdening a controller.
	
	\subsection{Latency-based Clustering Algorithm (LCA)} \label{lbc}
	
	%In short write in two lines about the subsubsections
	The Latency-based Clustering Algorithm (LCA) clusters the network in two phases: the first phase selects the cluster-centers and the second phase forms the clusters surrounding the cluster-centers.
	\subsubsection{Cluster-center selection}
	We determine footholds from which a cluster will be created, before forming a cluster, to ensure that the clusters are not concentrated in a certain region. Consequently, we re-cluster the network to avoid forming irregular clusters in terms of geographical shape and size. In \cite{aziz2019degree}, DBC places controllers based on inter-controller and intra-controller distances, while ensuring that these footholds, namely cluster-heads, are a minimum distance ($T_d$) apart from each other. However, the cluster-heads are randomly selected and the $T_d$ distance is calculated virtually. In this paper, we determine the foundations of the clusters based on their average distance from all other nodes. Accordingly, we name the foundations as \textit{cluster-centers} and propose a novel clustering algorithm LCA.
	
	%Rewrite Introduction to the Algorithm
	%\underline{This is the old paragraph:} Our previous work Degree-based Balanced Clustering (DBC) \cite{aziz2019degree} selects the nodes with the highest degrees in an unweighted network as cluster heads to reduce intra-cluster distances. Ensuring that the cluster heads are a minimum distance ($T_d$) apart from each other, DBC places controllers based on inter-controller and intra-controller distances. In this paper, we propose a novel clustering algorithm LBCA, which selects cluster-centers instead of cluster-heads as the foundations of the clusters. They ensure that the clusters are evenly distributed throughout the network and not centralized in a certain region.
	
	
	When a network is managed by a single controller, it should be placed at the center of the network to minimize the controller-to-switch delay. If $G$ represents such a network then the center of $G$ can be determined by minimizing the average or maximum delay from every other node \cite{wilson1979introduction}:
	
	\begin{equation} \label{eqn:avgDis}
	center_{avg} = \min_{s\in S}\bigg(\frac{\sum_{d\in S, d\ne s}T(s,d)}{|S|-1}\bigg)
	\end{equation}
	\begin{equation} \label{eqn:maxDis}
	center_{max} = \min_{s\in S}\bigg(max_{d\in S}\big(T(s,d)\big)\bigg)
	\end{equation}
	\begin{figure}
		\centering
		\includegraphics[width=0.9\linewidth]{Images/Aarnet.png}
		\caption{Existing network of Australia (AARNET \cite{knight2011internet}) showing the centers of the network.}
		\label{fig:aarnetcc}
	\end{figure}
	where, $center_{avg}$ and $center_{dia}$ are the centers $G$ in terms of average and maximum delays, respectively, and $T(s,d)$ is the shortest path distance from nodes $s$ to $d$. The maximum distance or worst-case latency (Equation \ref{eqn:maxDis}), when determines the center of the network \cite{wilson1979introduction}, can vary greatly in the presence of distant and isolated nodes (Figure \ref{fig:aarnetcc}). Conversely, the average case latency (Equation \ref{eqn:avgDis}) is less affected by outliers, therefore, we select the node with the minimum average distance ($center_{avg}$) as the center of the network \cite{wilson1979introduction}.
	
	For larger networks, when placing multiple controllers, each controller is placed in a sub-network which makes the center selection process complex. To ensure equal division of the network, the cluster-centers are expected to be equidistant from each other and the clusters must expand from the centers. This selection of centers in a network is a classical NP-hard problem - \textit{The vertex k-center problem} \cite{kariv1979algorithmic}, which has many sub-optimal approximations. Our algorithm LCA (Algorithm \ref{algo:lbc}) utilizes the latencies between switches to divide the network optimally while ensuring minimum overlapping among neighboring clusters.
	
	\begin{algorithm}
		\SetAlgoLined
		\KwResult{Set of Cluster-Centers, $CC$ }
		$T := shortest~path~delay~between~two~switches$\;
		for all $s\in S$, $\overline{T}_s := \frac{\sum_{s,d \in S, d \ne s}T(s,d)}{|S|-1}$\;
		$CC := \emptyset$, $k :=$ required number of controllers\;
		\While{$|CC| < k$}{
			$CC := CC \cup \{s_{cc}\}$ for all $s_{cc}\in S$, where $\overline{T}_{s_{cc}} \le \overline{T}_{t\in S}$\; 
			Create a new cluster $S_i$ which consists of $s_{cc}$ and $\big(\frac{|S|}{k}-1\big)$ nearest neighbors of $s_{cc}$ in terms of hop distance\;
			\ForEach{switch $s_i \in S_i$}{
				Subtract $\frac{T(s_i, s)}{|S|-1}$ from $\overline{T}_s$ for all ${s \in S-S_i}$
			}
			$S = S - S_i$
		}
		Form clusters $S_{i=1}^k$, each containing a cluster-center $CC_i$ and all its nearest nodes\;
		\caption{Latency-based Clustering Algorithm (LCA)} \label{algo:lbc}
	\end{algorithm}

	%Make the pseudocode simpler and change the paragraph below accordingly
	Initially, we calculate the delays between every possible pairs of nodes in terms of shortest source to destination path delays (Algorithm \ref{algo:lbc} Line 1). Using the attained delays, we determine the average delay $\overline{T}_{s\in S}$, of every node $s$ from every other node in the network $S$ (Algorithm \ref{algo:lbc} Line 2). Consequently, we select the first cluster-center with the minimum average delay and form a cluster including the nearest $\frac{|S|-1}{k}$ nodes in terms of hop-distance. The delays of the nodes of this cluster are not considered in the calculation of the average delays of the remaining nodes (Algorithm \ref{algo:lbc} Line 8). We select the node with the lowest average delay among the remaining nodes and include $\frac{|S|-1}{k}$ nodes again to this newly formed cluster. We continue the process until $k$ cluster-centers are selected.
	
	%Ideally, a network $G$ containing $|S|$ switches and $k$ controllers has $\frac{|S|}{k}$ switches in each cluster. The average delay (Equation \ref{eqn:avgDis}) of a node from all other nodes in the network increases gradually from the center towards the periphery. Accordingly, the node $s_{cc}$ with the minimum average delay $\overline{T_{s_{cc}}}$, is selected as the first cluster-center and the cluster is expanded hop by hop until the cluster-size reaches $\frac{|S|}{k}$ nodes. The nodes of the cluster are then removed from the network $S$ and their delays are subtracted from the average delays of the remaining nodes. This process is continued until $k$ cluster-centers have been selected.
	
	\subsubsection{Clustering-member selection}
	The cluster-centers of the previous phase are used to form the clusters in this phase. Each node of the network $G$ is included in the cluster of the nearest cluster-center in terms of the shortest path latency $T(i,j)_{i,j \in S}$. However, the shortest path is in terms of transmission delay instead of hop-count. The cluster-member selection is node after the cluster-center selection to avoid the formation of overlapping or isolated clusters.
	
	%The Controller Selection Algorithm (CSA) creates clusters once more from the cluster-centers generated by LBCA to avoid the formation of overlapping or isolated clusters and selects a controller position for each cluster. Each node is included in the cluster of the nearest clusters-center in terms of the shortest path distance $T(i,j)_{i,j \in S}$, which ends the cluster formation and initiates the controller selection process (Algorithm \ref{algo:csa}). It is to be noted that the shortest path distance is in terms of transmission delay (not hop-count).
	
	\subsection{Controller Selection Algorithm (CSA)} \label{csa}
	
	The Controller Selection Algorithm (CSA) selects a controller for each cluster and allows the network administrator to place controllers while prioritizing certain parameters.
	
	\begin{algorithm}
		\SetAlgoLined
		\KwResult{Set of Controllers, $C$ }
		$dis := all~possible~node~pair~shortest~distances$\;
		$CC_{i=1}^k :=$ \textbf{LBCA}~Cluster~Centers\;
		$\phi_{s\in S}(s) :=$ intra-cluster latency of $s$\;
		$\sigma_{s\in S}(s) :=$ inter-cluster latency of $s$\;
		Form clusters $S_{i=1}^k$, each containing a cluster-center $CC_i$ and all its nearest nodes\;
		\ForEach{node $s \in S$}{
			$\phi(s)_{s\in S_i}=\frac{\sum_{t\in S_i} dis(s,t)}{|S_i|}$\;
			$\sigma(s)_{s\in S_i}=\frac{\sum_{t\in (S-S_i)} dis(s,t)}{|S-S_i|}$\;
		}
		\ForEach{node $s$ in cluster $S_i \subset S$}{
			$s_c:=\min\bigg(\big( \phi(s)\times \overline{\sigma} \times \alpha \big) + \big( \sigma(s) \times \overline{\phi} \times (1-\alpha) \big) \bigg)$\;
			$C:=C \cup \{s_c\}$\;
		}
		\caption{Controller Selection Algorithm (CSA)} \label{algo:csa}
	\end{algorithm}
	Ideal controller positions have minimum distance from each other and the switches of the network in terms of propagation latency. However, both controller-to-controller and controller-to-switch latencies cannot be minimized simultaneously. Furthermore, the distance from a controller to any other controller or switch cannot be calculated without placing a controller beforehand, which results in a paradoxical scenario. Therefore, we utilize a controller selection method that replaces inter-controller and intra-controller delays with inter-cluster ($d$) and intra-cluster ($r$) latencies, respectively \cite{aziz2019degree}. A normalized constant $\alpha$, is introduced to control their priority when selecting controller positions. Consequently, the controller position ($C_i$) for a cluster $S_i$, is calculated as follows:
	
	\begin{equation} \label{eqn:intra}
	r_{\forall s\in S_i} = \frac{1}{|S_i|}\sum_{u\in S_i} T(s,u)
	\end{equation}
	
	\begin{equation} \label{eqn:inter}
	d_{\forall s\in S_i} = \frac{1}{|S-S_i|}\sum_{v\in (S-S_i)} T(s,v)
	\end{equation}
	
	\begin{equation} \label{eqn:totlat}
	D_i = \min\bigg(\big( r\times \beta_1 \times \alpha \big) + \big( d \times \beta_2 \times (1-\alpha) \big) \bigg)
	\end{equation}
	%Beta1 = d/(r+d) and Beta2 = r/(r+d)
	Here, $\beta_1$ is the normalization constant for intra-cluster latencies ($r$) and $\beta_2$ is the normalization constant for inter-cluster latencies ($d$). The normalization constants depend on average inter-cluster and intra-cluster latencies following the equations $\beta_1 = $.
	
	Here, $\overline{\phi}$ and $\overline{\sigma}$ are the  mean intra-cluster and inter-cluster distances, respectively. The highest possible value of $\alpha$ is $1$, which nullifies the effect of $\sigma$ and places controllers considering only intra-cluster distances. Meanwhile, for $\alpha = 0$, controllers are placed solely considering inter-cluster distances, and for $\alpha=0.5$, both intra-cluster and inter-cluster distances are prioritized equally. The value of $\alpha$ can be changed to better suit the requirement of the network administrator.
	
	\subsection{Best-first-search Load Balancing Algorithm (BLBA)} \label{blb}
	
	For a fixed controller-switch assignment scheme ($S\rightarrow C$), the loads of the controllers vary due to changing loads of the switches. However, once a controller is placed, changing its position is both costly and inefficient. To balance the constantly changing loads of the controllers, we propose a dynamic load balancing algorithm Best-first-search Load Balancing (BLBA, Algorithm \ref{algo:blb}) which uses the well-known Uninformed Search technique - Best-First Search (BFS). BLBA considers each possible controller-switch assignment scheme as a separate network state and the target is to reach the optimal state, where the loads of the controllers are balanced. Assuming that each controller has identical processing capacity and each switch has a varying load, we denote the loads of the switches as $l_1, l_2, \dots$ and so on. The total load of the network $S$, at any state, can be calculated as,
	
	\begin{equation}
	L_{net}=\sum_{i=1}^{|S|}l_i
	\end{equation}
	
	Therefore, the load of a controller in an ideally load-balanced network, in the target state should be $\frac{L_{net}}{k}$, where $k$ is the number of controllers. However, when switches are assigned to distant controllers to maintain an ideal load distribution, excess traffic may be generated. For example as shown in Figure \ref{fig:overlap}. The extra traffic contributes to an overall increase in latency and a decrease in network throughput. To avoid such overlapping of clusters, we prioritize distance over load-balancing and express the problem as a Heuristic (Informed) Search with the following foundations:
	
	
	\begin{figure}
		\centering
		\includegraphics[width=0.95\linewidth]{Images/Abilene_overlap.jpg}
		\caption{Redundant traffic is generated for new flow queries of switches 7 and 10 to controllers 9 and 6 respectively, which can be avoided by swapping the clusters of the switches} \label{fig:overlap}
	\end{figure}
	
	\subsubsection{Search Space and Root State}
	The entire search space is a graph where each node corresponds to a \textit{state}. A state is a valid controller-switch assignment scheme, where there are multiple controllers, and every switch is assigned to a single controller. The \textit{Root state} of the graph is the resultant assignment of switches when LBCA and CSA are applied on a network.
	
	\subsubsection{Child State}
	All the children of any node of the search space graph must be valid \textit{states}. Any \textit{Child state} is similar to its parent state except one switch, which is at the border of any cluster and is reassigned to the controller of the adjacent cluster. All such combinations constitute the set of Child states of any parent state.
	
	\subsubsection{Error Function}
	The error function $\varepsilon$ determines the acceptability of the current \textit{state} and can vary according to requirement. The function to minimize the maximum average controller response time is calculated as follows:
	\begin{equation}
	\varepsilon(state) = \sum_{i=1}^{k}\Bigg[\Big(L_i - \frac{L_{net}}{k}\Big)^2\Bigg]
	\end{equation}
	\begin{equation} \label{eqn:cload}
	L_i = \sum_{s\in S_i}l_{s}
	\end{equation}
	
	where, $L_i$ is the load of the $i^{th}$ controller, which is the cumulative load of the switches assigned to it. Squaring the differences gives more priority to controllers whose loads are more imbalanced compared to others.
	
	%Explain the figure properly and remove all the state definitions and make it simple
	\begin{figure*}
		\centering
		\begin{subfigure}{0.3\textwidth}
			\includegraphics[width=\linewidth]{Images/Aarnet_Graph.jpg}
			\caption{Original Aarnet Network (rearranged)}
			\label{fig:aarnet2009}
		\end{subfigure}
		~
		\begin{subfigure}{0.3\textwidth}
			\includegraphics[width=\linewidth]{Images/Aarnet_Load_1.jpg}
			\caption{Root state with no child state}
			\label{fig:aarnet2009l1}
		\end{subfigure}
		~
		\begin{subfigure}{\textwidth}
			\includegraphics[width=\linewidth]{Images/Aarnet_Load_2.jpg}
			\caption{Optimal assignment scheme achieved after three iterations}
			\label{fig:aarnet2009l2}
		\end{subfigure}
		\caption{The BLBA algorithm applied on Aarnet Network variations with randomized loads, where each switch is represented by a switch id, followed by its load and each cluster has its own controller position and load marked above.}
	\end{figure*}

	\subsubsection{Heuristic}
	Our ultimate goal is not an absolute and optimal solution, rather a local optimum where no clusters are overlapping. Therefore, we use a greedy heuristics for its simplicity and efficiency as its only disadvantage is it provides a sub-optimal solution. We select the above-mentioned error function as the heuristic and we use the Best First Search (BFS) technique with pruning to solve this problem, which selects the child state with the least error as the new assignment scheme in each iteration. When there is no child state with less error compared to the Root state (Figure \ref{fig:aarnet2009l1}), the child states are pruned to minimize computational complexity. Conversely, all the child states with equal or more error compared to the parent state are pruned at each iteration and the algorithm continues until the target state or a controller-switch assignment scheme with minimum error is achieved  (Figure \ref{fig:aarnet2009l2}). Extensive simulations suggest that the algorithm converges after a few iterations.
	
	%Explain the algorithm line by line
	\begin{algorithm}
		\SetAlgoLined
		\KwResult{Assignment of Switches, $S \rightarrow C$ }
		$S_{i=1}^k := $ \textbf{CSA} Clusters\;
		$state := S \rightarrow C$, current assignment of switches\;
		Set of all possible new states, $Pstates := \{state\}$\;
		\While{$Pstates \ne \emptyset$}{
			$state := \min\big(\varepsilon(Pstates)\big)$\;
			$Pstates := \emptyset$\;
			\ForEach{border switch $s\in S$}{
				New assignment $Nstate := state$\;
				Change assignment of switch $s$ to controller of adjacent cluster in $Nstate$\;
				\If{$\varepsilon(Nstate)<\varepsilon(state)$}{
					$Pstates := Pstates \cup \{Nstate\}$\;
				}
			}
		}
		\caption{Best-first-search Load Balancing Algorithm (BLBA)} \label{algo:blb}
	\end{algorithm}
	
	\section{Performance Analysis and Evaluation} \label{simulations}
	
	The proposed mechanism clusters the network, places controllers, and performs load balancing on the clustered network after placement. The following sections \ref{SimEnv} and \ref{PerfMetrics} give a detailed description of the simulation environment and the performance metrics. In Section \ref{optimumK} optimum values for the decision variables, $k$ and $\alpha$ are determined. Subsequently, in sections \ref{CPAnalysis} and \ref{LoadAnalysis}, our proposed algorithms are validated by comparing them with the state-of-the-art controller placement \cite{dbcp2017} and load balancing algorithms \cite{filali2018sdn}, respectively.
	
	\subsection{Simulation Environment} \label{SimEnv}
	The simulation environment is developed using a high-level language C++, to perform experiments on existing network topologies collected from the Internet Topology Zoo \cite{knight2011internet}. The Topology Zoo contains a total of 261 existing networks, out of which a few ($18$) have islands (isolated nodes). Therefore, we perform our simulations on the remaining networks. A summary of the experimental networks is given in Table \ref{tab:zooSummary}.
	
	\begin{table}
		\centering
		\caption{A summary of our Experimental Networks} \label{tab:zooSummary}
		\begin{tabular}{|l|c|}
			\hline
			\textbf{Category} & \textbf{Data} \\
			\hline
			Total number of networks & 243 \\
			\hline
			Number of unweighted networks & 134 \\
			\hline
			Maximum number of nodes & 754 \\
			\hline
			Minimum number of nodes & 4 \\
			\hline
			Networks with multi-edges & 82\\
			\hline
			Average Edge per Node & 1.285 \\
			\hline
		\end{tabular}
	\end{table}

	The initial weights of the links are their bandwidths in \textit{Gb/s} (Gigabits per second), which are converted into transmission latencies (milliseconds), assuming each control packet is 1500 bytes long. The maximum bandwidth is considered for links with variable bandwidths and all fiber-optic cables without available bandwidth information are assumed to have $1~Gb/s$ bandwidth. The networks with identical edge weights are considered as unweighted.
	
	We perform our load balancing simulations on the network with the highest number of nodes ($|S|=754$) to illustrate the performance of BLBA. The switches are assumed to have loads of 1000 to 5000 in terms of active flows per second, which is equivalent to the loads of data-center switches \cite{benson2010traffic}. We assume the network has $10$ controllers that are placed using LBCA and CSA, and each controller has a maximum processing capacity of $1000K~flows/s$ which is adequate to support the maximum load of the networks in our simulations.
	
	\subsection{Performance Metrics} \label{PerfMetrics}
	
	\begin{figure}
		\centering
		\includegraphics[width=0.95\linewidth]{Images/new_flow.jpg}
		\caption{Setup of a new flow in the flow tables of the switches in the network} \label{new_flow}
	\end{figure}
	
	SDN switches match every incoming packet with appropriate flow tables. The result of a match can either be a \textit{hit} - which means the appropriate flow is already in a flow table, or, a \textit{miss} - in which case the flow is new and the switch asks its assigned controller for the next course of action. The assigned controller calculates the path with the least delay for the flow and notifies the concerned switches to update their flow tables. However, for switches assigned to another controller, the corresponding controller is notified instead (Figure \ref{new_flow}). Therefore, the total time required to notify all the concerned switches about the new flow is the \textit{flow-setup latency}. We represent the average flow-setup latency ($\Omega_{avg}$) of the network as the average time to notify all possible pairs of switches in the network. For a network with $|S|$ switches, the average flow-setup latency can be calculated as follows:
	
	\begin{equation} \label{eqn:setupLatency}
	\Omega_{avg} = \frac{\sum_{s_i,s_d\in S} \left(dis(s_i,c_i)+ maxPath(s_i,s_d)\right)}{|S|\times |S-1|}
	\end{equation}
	
	\begin{equation}
	maxPath(s_i,s_d) = \max_{x\in path(i,d)}\left(dis(c_i,c_x)+dis(c_x,s_x) \right)
	\end{equation}
	
	where, $path(i,d)$ is the path with least delay from source $s_i$ to destination $s_d$, and $s_x$ is any switch in that path. The controllers of switches $s_i$ and $s_x$ are $c_i$ and $c_x$ respectively.
	
	The processing latency of the controllers increases significantly for an imbalanced network, which can be calculated if the loads of the switches and controllers are known. Accordingly, the overall flow setup latency for a network $S$ is the maximum time any switch needs to install a new-flow rule, including controller processing delays, and is denoted by:
	\begin{equation}
	\Omega_S = \max_{s_i\in S} \bigg( \Delta_{s_i}\times l_{s_i} \bigg)
	\end{equation}
	
	where $\Delta_{s_i}$ is the average time required for a switch $s_i$ to add a new flow to its flow table and $l_{s_i}$ is the switch load. Using the average flow-setup latency (Equation \ref{eqn:setupLatency}) and average controller response times (Equation \ref{eqn:cresponse}) of a network, $\Delta_{s_i}$ is derived as follows:
	\begin{equation}
	\Delta_{s_i} = \frac{\sum_{s_i,s_d\in S} \bigg[dis(s_i,c_i)+RT_{c_i}+maxPath(s_i,s_d) \bigg]}{|S|-1}
	\end{equation}
	
	\begin{equation}
	maxPath(s_i,s_d) = \max_{s_j\in path_{id}}\{dis(c_i,c_j)+RT_{c_j}+dis(c_j,s_j)\}
	\end{equation}
	
	where $RT_{c_i}$  and $RT_{c_j}$ are the average controller response times for controllers $c_i$ and $c_j$ respectively.
	
	\subsection{Decisive Variables} \label{optimumK}
	
	\begin{figure}
		\centering
		\includegraphics[width=0.95\linewidth]{Images/Abilene_Analysis.png}
		\caption{Average flow-setup latencies for varying values of $\alpha$ and $k$ in a network containing $|S|=11$ switches} \label{fig:abileneA}
	\end{figure}

	LBCA clusters the network into $k$ sub-networks and CSA places a controller in each sub-network using the constant $\alpha$, which is a real number ranging from $0$ to $1$. The constant dictates the placement of controllers by controlling the priority of intra-cluster and inter-cluster distances. Applying LBCA on a small network with varying values of $k$ and $\alpha$ (Figure \ref{fig:abileneA}) provides valuable insight on how the two variables affect the overall flow-setup latency of a network (Equation \ref{eqn:setupLatency}).
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=0.95\linewidth]{Images/k_vs_l.png}
		\caption{Decreasing average flow-setup latencies with respect to number of controllers ($k$) for different networks. As the networks have varying latencies, they are normalized for comparison.} \label{fig:KvsL}
		\centering
		\includegraphics[width=0.95\linewidth]{Images/cutoff.png}
		\caption{Gradually decreasing improvement ratio with respect to number of controllers ($k$) for networks of different sizes} \label{fig:cutoff}
	\end{figure}

	An increased number of clusters are formed when an excessively large amount of controllers are placed in a network. Consequently, the cluster-sizes are diminished, greatly reducing the number of viable controller positions in a specific cluster. Therefore, for a specific and large value of $k$, varying the value of $\alpha$ causes little or no change in placement and has no effect on overall flow-setup latency ($k=6$). For smaller values of $k$, the flow-setup latency gradually decreases and then increases ($k<5$). In some cases, the latency only increases as inter-controller distances increase ($k=5$), which indicates that no better placement is found for greater controller separation. The flow-setup latency is the lowest when $\alpha \ge 0.2$ and $\alpha \le 0.6$, which indicates that inter-controller communication contributes more to the flow-setup procedure when there are many controllers. However, in our experiments, we have used $\alpha=0.5$ to give equal priority to controller-to-switch and controller-to-controller communication.
	

	The flow-setup latency of a network decreases as the number of controllers increase, with a few exceptions due to variations in network topology (Figure \ref{fig:KvsL}). The rate of decrease is greater for smaller networks compared to larger networks as controller/switch ratio increase drastically for smaller networks. Accordingly, the setup latency is minimum when $k$ is equal to the total number of nodes in a network, which, however, invalidates one of the firsthand benefits of placing controllers (simplifying nodes and reducing costs). In order to determine the optimum number of controller $k$ for a network $S$, we define an improvement ratio:
	
	\begin{equation}
	Improvement~Ratio_k = \frac{Latency_1}{Latency_k\times k}
	\end{equation}
	
	where $Latency_1$ and $Latency_k$ are the flow-setup latencies when the number of controllers is 1 and $k$ respectively.
	
	The improvement ratio for a network decreases gradually with respect to increasing number of controllers (Figure \ref{fig:cutoff}). We observe that the improvement rate \textit{change} decreases drastically to less than $0.1$ from more than $0.2$ and $0.15$, after adding 4 controllers to the network where $|S|=64$ and 3 controllers to the other two networks, respectively. Therefore, we cease adding controllers when the improvement rate change drops below $0.1$. Consequently, the resultant average switch/controller ratio of the 238 networks is $12.79$. According to expert opinions \cite{heller2012latency}, a network with $34$ nodes requires approximately $3$ controllers to function efficiently and one more to handle failures, which supports our optimal $k$ derivation in terms of average switch/controller ratio.
	
	\section{Simulation Results} \label{simulationResults}
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{Images/forced_comparison.png}
		\caption{Comparison among LBCA+CSA, DBCP and DBC, in terms of normalized flow-setup latency} \label{fig:Fcomparison}
		~
		\centering
		\includegraphics[width=\linewidth]{Images/load_comparison_edit.png}
		\caption{Comparison between BLBA and MSDA in terms of load per controller} \label{fig:Lcomparison}
	\end{figure}

	\subsection{Controller Placement} \label{CPAnalysis}
	
	In this section, we evaluate our static controller placement method (LBCA+CSA) by comparing it to the well-known algorithm DBCP \cite{dbcp2017} and the algorithm DBC \cite{aziz2019degree}. DBCP places controllers based on the density of nodes and the minimum distance to higher density nodes. In order to compare the algorithms, we simulate both DBC and LBCA with the same number of controllers as DBCP when clustering the networks from the Zoo Topology. DBCP underperforms compared to LBCA and DBC when the network has high connectivity (e.g. star topology) or when all nodes have an equal density (e.g. ring topology). Our simulations using the remaining networks suggest that LBCA+CSA outperforms both DBCP and DBC in terms of flow-setup latencies.
	
	The flow-setup latency results of the simulations vary greatly for different networks. Therefore, we represent the latencies of DBCP and DBC as a ratio of the latencies of LBCA+CSA and plot their averages for a given range of network sizes (Figure \ref{fig:Fcomparison}). The average latency of all the networks with network sizes less than $10$ are plotted for $|S|=5$, those greater than 9 and less than 20 are plotted for $|S|=15$, and so on. Although DBC performs better for certain unweighted networks, LBCA+CSA outperforms both DBCP and DBC in 78\% and 72\% of the simulated networks, respectively.
	
	\subsection{Load Balancing} \label{LoadAnalysis}
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{Images/response_comparison.png}
		\caption{Gradually decreasing average response times for varying switch loads} \label{fig:Rcomparison}
		~
		\centering
		\includegraphics[width=\linewidth]{Images/omega_comparison.png}
		\caption{Comparison between BLBA and MSDA in terms of maximum flow-setup latency} \label{fig:Ocomparison}
	\end{figure}

	BLBA balances the loads of the controllers by swapping clusters of border nodes to avoid overlapping cluster formations. We set the maximum iteration limit of BLBA to $100$ and compare with the algorithm MSDA \cite{filali2018sdn, fragiadakis2016matching} in terms of maximum load imbalance. The loads of the switches are randomly assigned within the range of $1000$ to $5000$ with equal probability. Therefore, the average switch load is $2500 flows/s$ and the target controller load is $188.5K flows/s$ (Figure \ref{fig:Lcomparison}). The global precedence list of MSDA is calculated by multiplying transmission latency with average sojourn time or controller processing time. However, in our experiments, we observe that transmission latencies are greater than processing latencies, which results in load imbalance. Furthermore, when the maximum controller capacity is decreased substantially, MSDA underperforms as the preferences of the controllers and switches cannot be satisfied. The simulation suggests that BLBA outperforms MSDA in terms of controller load, especially for controllers 8 and 9 (Figure \ref{fig:Lcomparison}). Although the algorithm converges after 10 iterations approximately, the maximum iteration limit can be increased for better accuracy and performance.
	
	Figure \ref{fig:Rcomparison} represents the comparison between BLBA and MSDA in terms of maximum controller response times for different average switch loads. The response times increase with increasing switch loads as the controller loads also increase significantly. The comparison shows that BLBA outperforms MSDA in terms of average controller response times. The average controller response time is reduced by an average of $13\%$.
	
	We also compare both the algorithms in terms of maximum flow setup latency of a switch in Figure \ref{fig:Ocomparison} and observe that BLBA outperforms MSDA. The flow-setup latency for higher average switch loads shows the minimum change for MSDA as the controller-switch preferences are prioritized. BLBA on the other hand reduces latency as long as a local optimum is available. Consequently, the algorithm terminates if further optimization causes overlapping clusters, which is observed for an average switch load of 3500 flows/s as it produces unnecessary traffic (Figure \ref{fig:overlap}).
	
	\section{Conclusion} \label{conclusion}
	
	In this paper, we propose a novel controller assignment mechanism that clusters the network, places controllers, and balances loads to reduce the overall flow-setup latency of the network. Our proposed method addresses the Controller Placement Problem (CPP) and outperforms multiple state-of-the-art algorithms based on various performance metrics. Our proposed method has many advantages over other algorithms which include - having polynomial time complexity, providing an optimal number of clusters, decreasing controller response time, and flow-setup latency simultaneously. Our proposed algorithm BLBA can be extended to optimize any parameter by introducing and improving different error functions. Future work can include variable controller capacities when balancing controller loads. Our proposed method can also be extended to facilitate simultaneous optimization of several core network parameters, which will be significantly helpful for network operators.
	
	\section*{References}
	\bibliographystyle{elsarticle-num} 
	\bibliography{mybib}
\end{document}